# 15. Ансамбли классификаторов. Основные этапы работы типичного базового классификатора, возможность коррекции на разных этапах. Бэггинг и случайные подпространства. Бустинг. Случайный лес как композиция основных подходов к построению ансамбля.

https://dyakonov.org/2019/04/19/%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B8-%D0%B2-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8/

http://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B8%D0%B4%D1%8B_%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B5%D0%B9

http://www.machinelearning.ru/wiki/images/5/56/Guschin2015Stacking.pdf

#### Ансамбли классификаторов

**Ансамблем (Ensemble,Multiple Classifier System)** называется алгоритм, который состоит из нескольких алгоритмов машинного обучения, а процесс построения ансамбля называется ансамблированием (ensemble learning). Простейший пример ансамбля в регрессии – усреднение нескольких алгоритмов:

![f-1](https://alexanderdyakonov.files.wordpress.com/2019/04/f-1-1.png?w=700)

Алгоритмы из которых состоит ансамбль (в (1) – $b_t$) называются **базовыми алгоритмами (base learners).** 



Если рассматривать значения базовых  алгоритмов на объекте  как независимые случайные величины с одинаковым  матожиданием  и одинаковой конечной дисперсией, то понятно, что  случайная величина (1) имеет такое же матожидание, но меньшую дисперсию:

![f-2.png](https://alexanderdyakonov.files.wordpress.com/2019/04/f-2.png?w=700)

**Замечание.** Требование равенства матожиданий ответов базовых алгоритмов вполне  естественное: если мы берём алгоритмы из несмещённой модели, то их  матожидания не только совпадают, но и равны значению истинной метки.

Ансамбль алгоритмов (методов) — метод, который использует несколько  обучающих алгоритмов с целью получения лучшей эффективности  прогнозирования, чем можно было бы получить от каждого обучающего  алгоритма по отдельности.

В задачах классификации простейший пример ансамбля – **комитет большинства**:

![f-3.png](https://alexanderdyakonov.files.wordpress.com/2019/04/f-3.png?w=700)

где **mode** – мода (значение, которое встречается чаще других среди аргументов функции). 

Большинство приёмов в прикладном ансамблировании направлено на то, чтобы ансамбль был «достаточно разнообразным»**, тогда ошибки отдельных алгоритмов на отдельных объектах будут  компенсироваться корректной работой других алгоритмов. По сути, при  построении ансамбля:

- повышают качество базовых алгоритмов,
- повышают разнообразие (diversity) базовых алгоритмов.

#### Основные этапы работы типичного базового классификатора, возможность коррекции на разных этапах

В целом я хз, че тут говорить, но вот например я сгенерировал такой текст:

По сути внутри базового классификатора лежит какая-то из моделей -- линейная регрессия, решающее дерево, например. 

В случае бэггинга каждому базовому классификатору соответствует какая-то выборка из обучающего датасета, на ней каждый классификатор обучается и подстраивает свои параметры. Общая композиция из этих "недообученных" классификаторов затем одним из методов принимает решение, к какому классу принадлежит тот или иной объект.

В случае бустинга итоговый результат представляется в виде взвешенной суммы из корректирующих друг друга классификаторов. 

В то время как бустинг алгоритмически не ограничен, большинство  алгоритмов бустинга состоит из итеративного обучения слабых  классификаторов с целью сборки их в сильный классификатор. Когда они  добавляются, им обычно приписываются некоторым образом веса, которые,  обычно, связаны с точностью обучения. После того, как слабый  классификатор добавлен, веса пересчитываются, что известно как [«пересчёт весовых коэффициентов»](https://ru.wikipedia.org/w/index.php?title=Весовые_коэффициенты&action=edit&redlink=1)[[en\]](https://en.wikipedia.org/wiki/weighting). Неверно классифицированные входные данные получают больший вес, а правильно классифицированные экземпляры теряют вес[[nb 1\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-9). Тем самым последующее слабое обучение фокусируется больше на примерах,  где предыдущие слабые обучения дали ошибочную классификацию.

#### Бэггинг и случайные подпространства

Пусть имеется выборка *X* размера *N*. Количество классификаторов *M*

Алгоритм использует метод бутстрэпа (англ. *bootstrap*):

```
   Из всего множества объектов равновероятно выберем N объектов с возвращением. Это значит, что после выбора каждого из объектов мы будем возращать его в множество для выбора. Отметим, что из-за возвращения некоторые объекты могут повторяться в выбранном множестве.
   Обозначим новую выборку через X1
. Повторяя процедуру M
 раз, сгенерируем M
 подвыборок X1...XM
. Теперь мы имеем достаточно большое число выборок и можем оценивать различные статистики исходного распределения.
```

Шаги алгоритма бэггинг:

-  Генерируется с помощью бутстрэпа M выборок размера N для каждого классификатора.
-  Производится независимое обучения каждого элементарного  классификатора (каждого алгоритма, определенного на своем  подпространстве).
-  Производится классификация основной выборки на каждом из подпространств (также независимо).
-   Принимается окончательное решение о принадлежности объекта  одному из классов. Это можно сделать несколькими разными способами,  подробнее описано ниже.

![](img\Виды_ансамблей_Бэггинг_рус.png)

В методе случайных подпространств (random subspace method, RSM) базовые алгоритмы обучаются на различных подмножествах признакового описания, которые также выделяются случайным образом. Этот метод предпочтителен в задачах с большим числом признаков и относительно небольшим числом объектов, а также при наличии избыточных неинформативных признаков. В этих случаях алгоритмы,построенные по части признакового описания, могут обладать лучшей обобщающей способностью по сравнению с алгоритмами, построенными по всем признакам. Широко известным алгоритмом, использующим одновременно метод случайных подпространств и бэггинг, является случайный лес. Разбиение объектов в вершине случайного леса ищется среди случайного подмножества признаков, а обучение каждого дерева в композиции происходит на выборке, полученной с помощью операции бутстрапа.

#### Бустинг

https://neerc.ifmo.ru/wiki/index.php?title=%D0%91%D1%83%D1%81%D1%82%D0%B8%D0%BD%D0%B3,_AdaBoost

Бустинг основан на вопросе, поднятом Кернсом и [Вэлиантом](https://ru.wikipedia.org/wiki/Вэлиант,_Лесли) (1988, 1989)[[3\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-_ec01e06736d97577-3)[[4\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-_d5a47fc0ef9867e4-4): «Может ли набор слабых обучающих алгоритмов создать сильный обучающий алгоритм?». Слабый обучающий алгоритм определяется как [классификатор](https://ru.wikipedia.org/wiki/Задача_классификации), который слабо коррелирует с правильной классификацией (может пометить  примеры лучше, чем случайное угадывание). В отличие от слабого  алгоритма, сильный обучающий алгоритм является классификатором, хорошо  коррелирующим с верной классификацией.

Положительный ответ Роберта Шапирe в статье 1990 года[[5\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-_f79a06ed82a55228-5) на вопрос Кернса и Вэлианта имел большое значение для теории машинного обучения и [статистики](https://ru.wikipedia.org/wiki/Статистика), и привёл к созданию широкого спектра алгоритмов бустинга[[6\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-_e38de82ace1c77bb-6).

***Гипотеза о бустинге*** относилась к процессу настройки алгоритма слабого обучения для получения строгого обучения.  Неформально, спрашивается, вытекает ли из существования эффективного  алгоритма обучения, выходом которого служит гипотеза, эффективность  которой лишь слегка лучше случайного гадания (то есть слабое обучение),  существование эффективного алгоритма, который даёт гипотезу произвольной точности (то есть сильное обучение)[[3\]](https://ru.wikipedia.org/wiki/Бустинг#cite_note-_ec01e06736d97577-3). Алгоритмы, которые получают быстро такую гипотезу, становятся известны просто как «бустинг». 

**Бустинг.** Пошаговое наращивание ансамбля алгоритмов. Алгоритм, который присоединяется к ансамблю на шаге k обучается по выборке, которая формируется из объектов исходной обучающей выборки.

Классификаторы ансамбля строятся последовательно и на каждой итерации происходит коррекция (перевзвешивание) наблюдений обучающей выборки (на первой итерации веса всех наблюдений равны). Коррекция осуществляется таким образом, чтобы соответствующий классификатор делал меньше ошибок на тех наблюдениях, на которых часто делали ошибки классификаторы, построенные на предыдущих итерациях алгоритма. Кроме того, каждому классификатору приписывается некоторый вес исходя из количества допущенных им ошибок.

Например, один из первых алгоритмов бустинга Boost1 использовал ансамбль из 3-х моделей, первая из которых обучалась на всем наборе данных, вторая – на выборке примеров, в половине из которых первая дала правильные ответы, а третья - на примерах, где «ответы» первых двух разошлись. Т.е. происходит последовательная обработка примеров цепочкой классификаторов, причем так, что задача для каждого последующего становится труднее. Результат определяется путем простого голосования: пример относится к тому классу, который выдан большинством моделей ансамбля.

Развитием данного подхода явилась разработка более совершенного семейства алгоритмов бустинга AdaBoost, который может использовать произвольное число классификаторов и производить обучение на одном наборе примеров, поочередно применяя их на различных шагах.

#### Случайный лес как композиция основных подходов к построению ансамбля.

https://dyakonov.org/2016/11/14/%d1%81%d0%bb%d1%83%d1%87%d0%b0%d0%b9%d0%bd%d1%8b%d0%b9-%d0%bb%d0%b5%d1%81-random-forest/

**Решающие деревья** – классификация объекта с помощью ответов на иерархически организованную систему вопросов. Вопрос, задаваемый на последующем иерархическом уровне, зависит от ответа, полученного на предыдущем уровне.

![](img/360px-CART_tree_titanic_survivors_%28RU%29.png)

**RF (random forest)** — это множество решающих деревьев (ансамбль). В задаче регрессии их ответы усредняются, в задаче классификации принимается решение голосованием по большинству.  Все деревья строятся независимо по следующей схеме:

- Выбирается подвыборка обучающей выборки  размера samplesize (м.б. с возвращением) – по ней строится дерево (для  каждого дерева — своя подвыборка). (**бэггинг**)
- Для построения каждого расщепления в  дереве просматриваем max_features случайных признаков (для каждого  нового расщепления — свои случайные признаки). (**случайные подпространства**)
- Выбираем наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило,  до исчерпания выборки (пока в листьях не останутся представители только  одного класса), но в современных реализациях есть параметры, которые  ограничивают высоту дерева, число объектов в листьях и число объектов в  подвыборке, при котором проводится расщепление.

**Алгоритм случайного леса** сочетает в себе две идеи: метод бэггинга и метод случайных подпространств. Для полученных данных алгоритм создает множество деревьев принятия решений и потом усредняет результат их предсказаний (бэггинг). Случайность: если создать много одинаковых деревьев, то результат их усреднения будет обладать точностью одного дерева. На практике: из всего набора входных данных случайным образом выбирается некоторое количество столбцов и строк и строится первое дерево принятия решений. Такая процедура повторяется множество раз, на выходе получается множество деревьев => результат – класс, к которому отнесли большинство деревьев.





