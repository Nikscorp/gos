# 8. Качество сервиса в компьютерных сетях: модели распределения ресурсов сети и методы борьбы с перегрузками.

**Качество сервиса**

- Нет четкого определения
- Методы позволяющие обслуживать разные потоки данных с разным качеством 
- Методы распределения ресурсов сети между разными потоками данных 
- Методы обеспечения предсказуемого и согласованного поведения сети в условиях постоянно изменяющейся конфигурации 
- Методы повышения эффективности работы и утилизации оборудования сети

**Метрики качества сервиса **

- Уровень потерь (packet loss) — Доля пакетов, которые были отправлены, но не были доставлены получателю [проценты]
- Пропускная способность (bandwidth) — Количество данных, которые могут быть переданы в единицу времени [байты] 
- Задержка (delay) — Время передачи единицы данных по направлению от отправителя к получателю [секунды] 
- Вариация задержки, дрожание (jitter) — Разница между минимальной и максимальной задержками [секунды]

**Что такое управление качеством сервиса? **

- Методы позволяющие обслуживать разные потоки данных с разным качеством 
- Методы распределения ресурсов сети между разными потоками данных 
- Методы обеспечения предсказуемого и согласованного поведения сети в условиях постоянно изменяющейся конфигурации 
- Методы повышения эффективности работы и утилизации оборудования сети



### Перегрузка

**Перегрузка сети** в компьютерных сетях и теории очередей — состояние сети, при котором основные показатели качества обслуживания существенно ухудшаются. Возникает, когда на сетевой узел (например, коммутатор) поступает больше данных, чем он может обрабатывать/передавать. Типичные эффекты включают задержку в очереди, потерю пакетов или блокировку новых соединений. Перегрузки могут возникать как на отдельных участках сети (локальные перегрузки), так и распространяться на всю сеть (глобальные перегрузки).

Более формально: перегрузка — это явление, при котором увеличения нагрузки на сеть приводит к снижению пропускной способности (происходит это именно при переполнении очередей).

**Методы борьбы с перегрузкой:**

- Буферизация (не уверена, что это тут нужно)
  - На входе: Нет необходимости в сверх-быстрой памяти. Если пакеты из нескольких входных портов начинают конкурировать за один и тот же вход коммутационной фабрики, возникает блокировка пакетов, находящихся за ними — Head Of Line (HOL) Blocking. При равномерном распределении маршрутов передачи пакетов производительность коммутатора равна менее 59% показателя коммутатора с буферизацией на выходе.
  - На выходе
  - На самом деле на сегодняшний день наиболее распространены модели Combined Input Output Queuing (CIOQ)

- управление перегрузкой

**Управление перегрузкой TCP: задачи** 

- Соединения должны адаптироваться к качеству предоставленной линии связи и стремиться использовать предоставленные ресурсы максимально эффективно 
- Соединения должны автоматически распределять пропускную способность разделяемой ими линии связи справедливым образом

Более формально:

Алгоритм управления перегрузкой должен удовлетворять требованиям:

- Эффективность: сумма нагрузок источников (по сути скорость) в bottleneck узле должна быть как можно ближе к пропускной способности этого узла
- Справедливость: говорит о распределении нагрузок в bottleneck узле, есть разные индексы справедливости, например Jain fairness index и max-min.
  - Jain: $F(r_1,r_2,\dots r_n)=\frac{(\sum r_i)^2}{n(\sum r_i^2)}, r_i \in A_i$, где максимально справедливое распределение ресурсов достигается при $F=1$. $r_i$ — нагрузка, $A_i$ — множество потоков проходящих через bottleneck $i$, $n=|A_i|$.
  - Max-min: когда увеличение нагрузки любого из потоков ведет к уменьшению нагрузки другого с меньшой или такой же нагрузкой
- Сходимость: для данного критерия выделяют два аспекта
  - Отзывчивость (responsivness): скорость с который нагрузка $r_i(t)$ достигает критерия эффективности
  - Гладкость (smoothness): величина колебаний, после достижения критерия эффективности

**Управления перегрузкой TCP: принципы работы**

- Взаимодействующие с сетью — Сетевые устройства сигнализируют о возникновении перегрузки (TCP/ECN) 
- Без взаимодействия с коммутаторами — Перегрузка определяется косвенно (по потере пакета, увеличению задержки и т.д.) 
- Реактивные (как правило, loss based) — Детектируют возникновение перегрузок по факту 
- Проактивные (как правило, delay based) — Ограничивают пропускную способность соединения, предчувствуя скорую перегрузку

При отсутствии дополнительных сервисных пакетов отправитель получает информацию из ACK-сообщений, поступающих к нему спустя один Round Trip Time (RTT), следовательно отправитель способен адаптироваться к состоянию сети не быстрее, чем за RTT.

**Примеры**

- TCP Tahoe
  - медленный старт: начинаем с cwnd=1, потом *2, до порога slow-start threshold, ssthresh.
  - предотвращение перегрузки (congestion-avoidance): +1
  - таймаут или 3 dupACK: cwnd=1, медленный старт, ssthresh=ssthresh/2
- TCP Reno
- Cubic
- Data Center TCP
- etc



### Модели распределения ресурсов

**Проблема эффективного распределения ресурсов**

Проблема обеспечения качества связана с проблемой распределения сетевых ресурсов между потоками данных 

- Проблему распределения ресурсов можно формализовать как задачу оптимизации 
- Чем больше ресурсов вовлечено в обслуживание потока, тем выше качество его соединения 
- Чем большее количество ресурсов позволяет задействовать модель распределения, тем выше эффективность сети, и тем больший уровень утилизации достигается. Чем выше уровень утилизации, тем лучше отношение производительности сети к стоимости сетевой инфраструктуры

Три модели обеспечения QoS:

- Best Effort — никакой гарантии качества. Все равны.
- IntServ — гарантия качества для каждого потока. Резервирование ресурсов от источника до получателя.
- DiffServ — нет никакого резервирования. Каждый узел сам определяет, как обеспечить нужное качество.

**Модель Интегрированных Сервисов (IntServ)**

*Заблаговременное резервирование ресурсов для потока на всём протяжении от источника до получателя.*

Для модели IntServ требуется сигнализационный протокол (например RSVP), который до установки сессии или начала обменом данными выделит требуемые ресурсы на каждом сетевом устройстве.

Говорят, что IntServ — мертворожденный слон. В некотором смысле современная инкарнация IntServ  —  это MPLS TE с адаптированной под передачу меток версией RSVP — RSVP TE. Хотя здесь, конечно же не End-to-End и не per-flow.

Мультимедийный трафик в сети:

- Как оградить TCP трафик от мультимедийных данных, передающихся через UDP?

- Как обеспечить качество соединения?

- Гарантированный уровень качества можно обеспечить лишь с помощью резервирования ресурсов — закрепления части ресурсов сети за конкретным потоком данных.
  Основная идея — прокладывание маршрутов с заданным качеством путём предварительного
  резервирования ресурсов на оборудовании 

- Модель лишь расширяет архитектуру Интернета, сохраняется совместимость с best-effort

- Модель особенно эффективна при многоадресной передаче данных

- Допускаются накладные расходы на предварительное прокладывание маршрута

- всё или ничего — модель или гарантирует соединение нужного качества, или отказывается
  предоставить какое-либо соединение.

  **Основные компоненты модели IntServ**

- Классификатор (classifier) — Разделение пакетов на классы обслуживания

- Планировщик (scheduler) — Обеспечение выполнения требований QoS

- Контроль доступа (admission control) — Оценка возможности добавления потоков

- Протокол резервирования ресурсов — Резервирование ресурсов вдоль маршрута

**Расчёт и обеспечение качества соединений**

- Распределение по очередям на входящих и исходящих интерфейсах коммутатора 
- Использование policing & shaping для формирования нужного профиля потоков 
- Установка надлежащих дисциплин сброса пакетов при их постановке в очереди и выборки пакетов из очередей 
- Настройка алгоритмов планирования коммутационной матрицы





**Модель Дифференцированных Сервисов (DiffServ)**

Когда в конце 90-х стало понятно, что End-to-End подход IntServ в IP провалился, в IETF созвали в 1997 рабочую группу «Differentiated Services», которая выработала следующие требования к новой модели QoS:

- Никакой сигнализации.
- Основан на агрегированной классификации трафика, вместо акцента на потоках, клиентах итд.
- Имеет ограниченный и детерминированный набор действий по обработке трафика данных классов.

Стоит обратить внимание, что название DiffServ — это не антитеза IntServ. Оно отражает, что мы дифференцируем сервисы, предоставляемые различным приложениям, а точнее их трафику, иными словами разделяем/дифференцируем эти типы трафика.
IntServ делает то же самое — он различает типы трафика BE и Real-Time, передающиеся на одной сети. Оба: и IntServ и DiffServ — относятся к способам дифференциации сервисов.

Модель поведения определяется набором инструментов и их параметров: Policing, Dropping, Queuing, Scheduling, Shaping.

1. Прежде всего нужно определить к какому классу сервиса относится трафик — классификация (**Classification**). Каждый узел самостоятельно классифицирует поступающие пакеты. 
2. После классификации происходит измерение (**Metering**) — сколько битов/байтов трафика данного класса пришло на маршрутизатор.
3. На основе результатов пакеты могут окрашиваться (**Coloring**): зелёный (в рамках установленного лимита), жёлтый (вне лимита), красный (совсем берега попутал).
4. Если необходимо, далее происходит полисинг (**Policing**). Полисер на основе цвета пакета назначает действие по отношению к пакету — передать, отбросить или перемаркировать.
5. До того, как пакет попадёт в очередь, он может быть отброшен (**Dropper**), если очередь заполнена
6. После этого пакет должен попасть в одну из очередей (**Queuing**). Для каждого класса сервиса выделена отдельная очередь.
7. На выходе из очереди работает шейпер (**Shaper**), задача которого очень похожа на задачу полисера — ограничить трафик до заданного значения.
8. Все очереди в итоге должны слиться в единый выходной интерфейс. Есть специальный диспетчер (**Scheduler**), который циклически вынимает пакеты из разных очередей и отправляет в интерфейс (**Scheduling**). На самом деле связка набора очередей и диспетчера — самый главный механизм QoS, который позволяет применять разные правила к разным классам трафика, одним обеспечивая широкую полосу, другим низкие задержки, третьим отсутствие дропов.
9. Далее пакеты уже выходят на интерфейс, где происходит преобразование пакетов в поток битов — сериализация (**Serialization**) и далее сигнал среды.

В DiffServ поведение каждого узла независимо от остальных, нет протоколов сигнализации, которые бы сообщили, какая на сети политика QoS. При этом в пределах сети хотелось бы, чтобы трафик обрабатывался одинаково. Если всего лишь один узел будет вести себя иначе, вся политика QoS псу под хвост.
Для этого, во-первых, на всех маршрутизаторах, настраиваются одинаковые классы для них, а во-вторых, используется маркировка (**Marking**) пакета — его принадлежность определённому классу записывается в заголовок (IP, MPLS, 802.1q).
И красота DiffServ в том, что следующий узел может довериться этой маркировке при классификации.

Кратко:

- Каждый маршрутизатор имеет несколько предопределённых классов обслуживания

- Пограничные маршрутизаторы определяют класс потока, маркируют его пакеты dscp метками и проводят traffic conditioning — используют инструменты policing & shaping для установки нужного профиля трафика

- На внутренних маршрутизаторах пакеты с более высоким приоритетом получают большую долю ресурсов, и наоборот

  

  **Стандартные классы обслуживания DiffServ**

- Default Forwarding (DF) — Обычно обслуживается по best-effort

- Expedient Forwarding (EF) — Идёт через очередь с высшим приоритетом, маленькие delay, jitter & loss

- Assured Forwarding (AF) — Идёт через менее приоритетную очередь, охватывает несколько классов с разной политикой сброса при заполнении очереди

- Преимущества

  - Отсутствие внутренней фрагментации
  - Высокая степень утилизации оборудования
  - Простота реализации в аппаратуре
  - Хорошая масштабируемость

- Недостатки
  - Не предоставляет гарантий качества
  - Метрики качества не рассчитываются явно
  - Ограниченное количество классов качества

 