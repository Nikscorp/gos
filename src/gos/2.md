## 2. Архитектурные особенности графических процессоров, направленные на массивно параллельные вычисления. Методы эффективной организации параллельных вычислений на графических процессорах.

https://www.iis.nsk.su/files/articles/sbor_kas_16_poletaev.pdf

https://vk.com/@physics_math-graficheskii-processor-ili-gpu

http://hpc-education.unn.ru/files/schools/hpc-2014/gpu/Lecture1_IntroToGPGPU.pdf

http://elar.urfu.ru/bitstream/10995/40616/1/978-5-7996-1722-6_2016.pdf

http://www2.rsuh.ru/binary/2632507_99.1424349071.26912.pdf

#### Архитектурные особенности

GPU (Graphics Processing Unit) предназначен для вычислений: 

+ параллельных по данным: одна и та же операция выполняется над многими данными параллельно,

+ в которых отношение вычислительных операций к числу операций по доступу к памяти велико.

  ![](img\gpuarch.PNG)

Высокая вычислительная мощность GPU  объясняется особенностями архитектуры. Современные CPU содержат  несколько ядер, тогда как графический процессор изначально создавался  как многопоточная структура с множеством ядер. Если архитектура CPU  предполагает последовательную обработку информации, то GPU исторически  предназначался для обработки компьютерной графики, поэтому рассчитан на  массивно параллельные вычисления.

CPU лучше работает с  последовательными задачами. При большом объёме обрабатываемой информации очевидное преимущество имеет GPU. Условие только одно — в задаче должен наблюдаться параллелизм.

Графический процессор может выполнить лишь часть операций, которые может выполнить центральный процессор, но он делает это с невероятной  скоростью. GPU будет использовать сотни ядер, но для достижения высоких скоростей GPU должен выполнять однообразные операции.

Выбор концепции SIMD для графических процессоров обусловлен тем, что она обеспечивает параллельное использование большого количества «вычислителей» без явного управления ими: распределения задач, синхронизации вычислений и коммуникации между параллельными расчетами. 

Тем не менее, центральные процессоры более гибкие, чем графические.  Центральные процессоры имеют больший набор инструкций, поэтому они могут выполнять более широкий диапазон функций. Также CPU работают на более  высоких максимальных тактовых частотах и имеют возможность управлять  вводом и выводом компонентов компьютера в отличии от GPU.

Есть множество различий и в поддержке многопоточности. CPU исполняет 1-2 потока вычислений на одно процессорное ядро, а видеочипы могут поддерживать до 1024 потоков на каждый мультипроцессор, которых в чипе несколько штук. И если переключение с одного потока на другой для CPU стоит сотни тактов, то  GPU  переключает несколько потоков за один такт.

Различен и принцип работы с памятью у GPU и CPU. Так, все современные GPU имеют несколько контроллеров  памяти, да и сама графическая память более быстрая, поэтому графические  процессоры имеют гораздо б*о*льшую пропускную способность памяти, по сравнению с универсальными процессорами, что также весьма важно для  параллельных расчетов, оперирующих огромными потоками данных.

![](img\cpu_gpu.PNG)

В универсальных процессорах б*о*льшую часть площади кристалла занимают различные буферы команд и данных,  блоки декодирования, блоки аппаратного предсказания ветвления, блоки  переупорядочения команд и кэш­память первого, второго и третьего  уровней. Все эти аппаратные блоки нужны для ускорения исполнения  немногочисленных потоков команд за счет их распараллеливания на уровне  ядра процессора. Сами же исполнительные блоки занимают в универсальном процессоре относительно немного места.

В графическом процессоре, наоборот, основную площадь занимают именно  многочисленные исполнительные блоки, что позволяет ему одновременно  обрабатывать несколько тысяч потоков команд.

#### Методы эффективной организации параллельных вычислений на графических процессорах

GPGPU – технология  использования  графического  процессора  для  выполнения расчетов в приложениях общих вычислений. Это стало возможным благодаря добавлению программируемых шейдерных блоков и более высокой арифметической точности растровых контейнеров, что позволяет использовать потоковые процессоры для неграфических вычислений.

На сегодняшний день технология GPGPU реализована несколькими производителями:

+ Khronos Group: OpenCL – язык программирования задач общего назначения, связанных с вычислениями на различных графических и центральных процессорах. 

+ Компания nVidia: CUDA – технология GPGPU, позволяющая реализовывать на языке Си(или других языках программирования)вычислительные алгоритмы,  выполняемые только на устройствах компании nVidia.

Особо значимое ускорение в GPGPU можно получить, если одни и те же инструкции применяются к огромным массивам данных. 

Следующим требованием можно назвать отсутствие взаимодействий между обрабатываемыми потоками или «слабое» взаимодействие. 

Потоковая обработка данных особенно эффективна для алгоритмов, обладающих следующими свойствами, характерными для задач физического и математического моделирования:

+ большая плотность вычислений — велико число арифметических операций, приходящихся на одну операцию ввода‑вывода  (например,  обращение  к  памяти).  Во  многих  современных  приложениях  обработки  сигналов  она  достигает  50:1,  причем  со сложностью алгоритмов увеличивается;
+ отсутствие в алгоритмах множественного ветвления; 
+ локальность данных по времени — каждый элемент загружается и обрабатывается за время, малое по отношению к общему времени обработки, после чего он больше не нужен. В результате в памяти потокового процессора для каждого «вычислителя можно хранить только данные, необходимые для обработки одного элемента, в отличие от центральных процессоров с моделью произвольно зависимых данных.

+ одна и та же последовательность вычислений, применяемая к разным данным

+ могут быть разбиты на подзадачи одинаковой сложности (подзадача будет решаться блоком нитей)

+ каждая подзадача может быть выполнена независимо от всех остальных, нет потребности в глобальной синхронизации


Возможные случаи параллелизма:

+ Параллельные копирование и выполнение кода на GPU
+ Параллельное выполнение кода на GPU

Если отсутствует возможность параллельного копирования памяти в обе стороны, то неправильный порядок отправки команд может привести к простою.

MPI + OpenMP + CUDA - хорошо гармонируют, так как MPI - ускорение экстенсивным путём, между процессорами, OpenMP - простое ускорение экстенсивным путём внутри процессора, а CUDA - ускорение интенсивным путём однотиповых вычислений.

Один CPU поток может управлять несколькими GPU, для этого нужно лишь переключать контексты.