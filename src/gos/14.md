Арчиловское: https://drive.google.com/drive/folders/0B3XUBeyj27tAaHBQSm56LU1zMVE

# 14. Cредние и эмпирические операционные характеристики стратегий распознавания (классификаторов, регрессий). Проблема переобучения. Проблема устойчивости решений. Роль обучающей, валидационной и контрольной выборок при построении распознающей системы. Скользящий контроль (кросс-валидация). Регуляризация на примере линейной регрессии

#### Cредние и эмпирические операционные характеристики стратегий распознавания (классификаторов, регрессий)

Среди задач обучения с учителем можно выделить 2 основные:

+ классификация
+ регрессия

**Классификатором** называется следующее отображение 
$$
\hat{c}: X \rightarrow C, где\ C = \{C_1, C_2, ..., C_k\} - конечное\ множество\ классов
$$
Проблема обучения для классификации -- обучить такую аппроксимацию $ \hat{c} $ истинной помечающей функции $c$. 

> Примеры классификации: определить кошка, собака или какое-либо еще животное на фотографии (многоклассовая); определить есть ли кошка на фотографии или нету (бинарная).

Для классификаторов оценить качество можно построив **матрицу ошибок**. Предположим, что некоторые данные можно разделить на 2 класса (бинарная классификация).  Таким образом, матрица будет выглядеть следующим образом

|               | $y = 1$                        | $y = 0$                        |
| ------------- | ------------------------------ | ------------------------------ |
| $\hat{y} = 1$ | True Positive                  | False Positive (ошибка 1 рода) |
| $\hat{y} = 0$ | False Negative (ошибка 2 рода) | True Negative                  |

$y$ -- истинный класс объекта

$\hat{y}$ -- предсказанный класс классификатором

Соответственно, на диагонали подобной матрицы будет находиться количество объектов распознанных правильно. В остальных местах -- ошибки. Отмечу также, что подобную матрицу можно построить и для многоклассовой классификации ($|C| > 2$).

> В зависимости от постановки исходной задачи ошибки 1 и 2 рода показывают разное. Например, в задаче по определению оттока абонентов, ошибкой первого рода  будет принятие лояльного абонента за уходящего, так как наша [нулевая гипотеза](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors) состоит в том, что никто из абонентов не уходит, а мы эту гипотезу  отвергаем. Соответственно, ошибкой второго рода будет являться "пропуск" уходящего абонента и ошибочное принятие нулевой гипотезы.

 ![](img\precall.png)

По такой матрице можно рассчитать различные **показатели качества классификатора** на размеченной выборке:

+ accuracy (доля правильных ответов алгоритма) = $\frac{TP + TN}{TP + FP + TN + FN}$ -- почти не используется из-за проблем с несбалансированными классами.

+ precision (точность)  = $\frac{TP}{TP + FP}$

+ recall (полнота) = $\frac{TP}{TP + FN}$

**Precision** можно интерпретировать как долю объектов, названных  классификатором положительными и при этом действительно являющимися  положительными, а **recall** показывает, какую долю объектов положительного  класса из всех объектов положительного класса нашел алгоритм. Precision и recall не зависят, в отличие от accuracy, от соотношения  классов и потому применимы в условиях несбалансированных выборок.

https://habr.com/ru/company/ods/blog/328372/

https://en.wikipedia.org/wiki/Precision_and_recall

Рассмотрим задачу регрессии. **Оценочной функцией** называется отображение:
$$
\hat{f} : X \rightarrow \R
$$
Проблема обучения регрессии заключается в построении оценочной функции по примерам $(x_i, f(x_i))$. 

> Примеры: задача поиска оценочной функции для индекса Доу-Джонса или для FTSE 100, исходя из выбранных экономических показателей. Также подобная функция может называться *гипотезой*.

Регрессионные модели рассчитываются путем применения функции потерь к **невязкам** $f(x) - \hat{f}(x)$ (для упрощения $y - \hat{y}$) -- отличие предсказания $\hat{y}$ от истинного значения $y$

Несколько популярных **функций потерь** $\mathcal{L}(\hat{y}, y)$ -- 

MAE -- Mean Absolute Error = $\frac{1}{m}|y - \hat{y}|$

MSE -- Mean Squared Error = $\frac{1}{m}(y - \hat{y})^2$

где m -- количество элементов x

(у этих функций потерь есть еще некоторые вероятностные интерпретации + гипотезы накладываемые на параметры, но давайте не будем об этом)

**Риск**, ассоциированный с гипотезой $\hat{f}(x)$, определяется как математическое ожидание функции потерь:
$$
R(h) = \mathbb{E}[\mathcal{L}(\hat{f}(x), y)]
$$
Высшей целью алгоритма обучения будет являться поиск такой гипотезы $\hat{f}^{*}$ в фиксированном классе функций $H$, для которой подобный риск $R(\hat{f})$ *минимален*:
$$
\hat{f}^{*} = \underset{\hat{f} \in H}{argmin} R(\hat{f})
$$
https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D1%8D%D0%BC%D0%BF%D0%B8%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B3%D0%BE_%D1%80%D0%B8%D1%81%D0%BA%D0%B0

> ================

> Текст для дискуссии про эту часть билета:

> Не знаю, что означает "средние и эмпирические" вот из билетов:

> Эмпирические методы оценки обобщающей способности - методы основанные на контрольной выборке.

> Средние операционные характеристики распознавания - ??? - возможно оценка обобщающей способности на самой обучающей выборке???

> Предполагаю что эмпирически -- глазами посмотреть красиво/некрасиво (пример: фильтр в инстаграмме). Но инфы как-то мало. 

> =======

#### Проблема переобучения

Основным способом поиска закономерностей (процесса обучения) является поиск в некотором априори заданном семействе алгоритмов прогнозирования $M'= {A : X' → Y'}$ алгоритма, наилучшим образом аппроксимирующего связь переменных из набора $X_1 , ... , X_n$ с переменной $Y$ на обучающей выборке, где $X'$ – область возможных значений векторов переменных $X_1 , ... , Xn$(известные переменные); Y' – область возможных значений переменной Y (прогнозируемая величина).

​     Расширение модели $M' = {A: X' → Y'}$ всегда приводит к повышению точности аппроксимации на обучающей выборке. Однако повышение точности на обучающей выборке, связанное с увеличением сложности модели, часто не ведет к увеличению обобщающей способности. Более того, обобщающая способность может даже снижаться. Различие между точностью на обучающей выборке и обобщающей способностью при этом возрастает. Данный эффект называется **эффектом переобучения**.

**Переобучение**, **переподгонка** (overtraining, overfitting) — нежелательное явление, возникающее при решении задач [обучения по прецедентам](http://www.machinelearning.ru/wiki/index.php?title=Обучение_по_прецедентам), когда вероятность ошибки обученного алгоритма на объектах [тестовой выборки](http://www.machinelearning.ru/wiki/index.php?title=Тестовая_выборка) оказывается существенно выше, чем средняя ошибка на [обучающей выборке](http://www.machinelearning.ru/wiki/index.php?title=Обучающая_выборка).  Переобучение возникает при использовании избыточно сложных [моделей](http://www.machinelearning.ru/wiki/index.php?title=Модель_зависимости).

*Обучение по прецедентам*, или *индуктивное обучение*, основано на выявлении общих закономерностей по частным [эмпирическим данным](http://www.machinelearning.ru/wiki/index.php?title=Выборка).

![](img\LsmRunge-detailed.png)

   Пример: 

> Рассмотрим задачу аппроксимации вещественной функции $y(x) = \frac1 {1+25x^2}$ по обучающей выборке из 50 точек $X^m = \left\{ x_i = 4\frac{i-1}{m-1}-2 \right\}$. Это равномерная сетка на отрезке $[-2,2]$. 

> В качестве модели рассмотрим полиномы заданной степени $p$:

$$
a(x, w) = w_0 + w_1x + ... + w_px^p
$$
> В качестве метода обучения возьмём [метод наименьших квадратов](http://www.machinelearning.ru/wiki/index.php?title=Метод_наименьших_квадратов):

$$
\sum_{i=1}^{m}(y(x_i) - a(x_i, w))^2 \rightarrow \underset{w}{min}
$$
> Таким образом, функция потерь квадратична: $\mathcal{L}(a,x) = \bigl( y(x) - a(x) \bigr)^2$.

> Возьмём контрольную выборку — также равномерную сетку на отрезке $[-2,2]$, узлы которой находятся в точности между узлами первой сетки: $X^k = \Bigl\{ x'_i = 4\frac{i-0.5}{m-1}-2 \Bigr\}$.

> Зададимся вопросом:  что будет на контрольной выборке при увеличении степени полинома $p$ Степень связана с числом свободных параметров модели, то есть играет роль сложности модели. 

> Ниже показаны графики самой выборки и аппроксимирующей функции:

-  при ![p=20](http://www.machinelearning.ru/mimetex/?p=20) — оптимальная сложность модели. 
-  при ![p=40](http://www.machinelearning.ru/mimetex/?p=40) — неустойчивость и переобучение. 

![](img\LsmRunge20.png)

![](img\LsmRunge40.png)

> http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5

> Еще такая картинка может помочь

![](img\bias-variance.png)

> Для этого требуется понимать, что мы можем разложить ошибку на bias-variance,

$$
\large \begin{array}{rcl} \text{Err}\left(\overline{x}\right) &=& \mathbb{E}\left[\left(y - \hat{f}\left(\overline{x}\right)\right)^2\right] \\ &=& \sigma^2 + f^2 + \text{Var}\left(\hat{f}\right) + \mathbb{E}\left[\hat{f}\right]^2 - 2f\mathbb{E}\left[\hat{f}\right] \\ &=& \left(f - \mathbb{E}\left[\hat{f}\right]\right)^2 + \text{Var}\left(\hat{f}\right) + \sigma^2 \\ &=& \text{Bias}\left(\hat{f}\right)^2 + \text{Var}\left(\hat{f}\right) + \sigma^2 \end{array}
$$

+ > квадрат смещения Bias – средняя ошибка по всевозможным наборам данных;

+ > дисперсии Var -- вариативность ошибки, то, на сколько ошибка будет отличаться, если обучать модель на разных наборах данных;

+ > ошибка $\sigma^2$ является неустранимой

> читать подробнее здесь: https://habr.com/ru/company/ods/blog/323890/

#### Проблема устойчивости решений

Под **устойчивыми** обучающими алгоритмами понимаются такие, которые дают решение, незначительно изменяющееся при малом изменении обучающей выборки.

Для многомерной линейной регрессии:

 (Задача восстановления линейной регрессии - задача обучения по прецедентам при $Y \rightarrow \R$, связь задается в виде $Y = β_0 + β_1X_1 + . . . + β_nX_n + ε$). При вычислении оценки вектора параметров $β = (β_0 , ..., β_n )$ в случае многомерной линейной регрессии удобно использовать матрицу $X $размера $m × (n + 1)$ , которая строится по обучающей выборке. j-я строка матрицы $X$ представляет собой вектор значений переменных (признаков)  вида $1, X_1 , ... , X_n$ для объекта $s_j$ c одной добавленной слева компонентой, содержащей 1 (для $\beta_0$).

Связь $Y$ с признаками $X_1 , . . . , X_n$ на объектах обучающей выборки может быть описана с помощью матричного уравнения $y = βX^T + ε$ , где $ε = (ε_1 , ... , ε_m )$ - вектор ошибок прогнозирования для объектов из выборки. Необходимым условием минимума функционала метода наименьших квадратов (МНК) является выполнение системы из $ n + 1$ уравнений ( равенство нулю производных по каждой переменной $β_0, ..., β_n$ ). 

В матричной форме эта система может быть записана в виде : $−2X^T y^T + 2X^T Xβ^T = 0$. Решение этой системы существует, если $det(X^TX)$ не равен 0. При сильной коррелированности одной из переменных ${ X_1 , . . . , X_n }$ на выборке с какой-либо линейной комбинацией других переменных значение $det(X^{T}X)$ оказывается близким к 0. При этом вычисленный вектор оценок $β^T$ может сильно изменяться при относительно небольших чисто случайных изменениях вектора $y = (y_1 , . . . , y_m )$ . 

Данное явление называется **мультиколлинеарностью**. Оценивание регрессионных коэффициентов с использованием МНК при наличии мультиколлинеарности оказывается неустойчивым. Также, $det(X^TX) = 0$ при $n + 1 > m$. Поэтому МНК не может использоваться для оценивания регрессионных коэффициентов, когда число переменных превышает число объектов в обучающей выборке. На практике высокая устойчивость достигается только, когда число объектов в выборках по крайней мере в 3-5 раз превышает число переменных.

#### Роль обучающей, валидационной и контрольной выборок при построении распознающей системы

Предположим, что задача прогнозирования решается для некоторого процесса или явления F . Множество объектов, которые потенциально могут возникать в рамках F , называется генеральной совокупностью Ω .

​     Поиск алгоритма осуществляется по выборке прецедентов, которая обычно является случайной выборкой объектов из Ω с известными значениями $Y, X_1 , . . . , X_n$ . Выборку прецедентов также принято называть **обучающей выборкой**.

​     Обобщающая способность может оцениваться по случайной выборке объектов из одной и той же генеральной совокупности, соответствующей исследуемому процессу, которую принято называть **контрольной выборкой**. Контрольная выборка не должна содержать объекты из обучающей выборки.

Может быть задано несколько семейств алгоритмов прогнозирования.

\-    Обучающая выборка используется для выбора алгоритма из каждого семейства

\-    **Валидационная выборка** используется для выбора того семейства алгоритмов, для которого после обучения распознающая система наилучшая

\-    Контрольная выборка определяет качество обученной распознающей системы.

Валидационная выборка используется для настройки структуры распознающей системы (какое семейство алгоритмов нам больше подходит, гиперпараметры модели(задаются человеком)).

Контрольная выборка используется для оценки работы обученного классификатора.

Валидационную выборку нельзя использовать в качестве контрольной, потому что валидационная выбирала наилучший классификатор, а потому он покажет заниженную оценку ошибки для валидационной выборки. 

#### Скользящий контроль (кросс-валидация)

**Скользящий контроль** или **кросс-проверка** или **кросс-валидация** (cross-validation, CV) — процедура эмпирического оценивания [обобщающей способности](http://www.machinelearning.ru/wiki/index.php?title=Обобщающая_способность) алгоритмов, [обучаемых по прецедентам](http://www.machinelearning.ru/wiki/index.php?title=Обучение_по_прецедентам).

Фиксируется некоторое множество разбиений исходной выборки на две подвыборки: [*обучающую*](http://www.machinelearning.ru/wiki/index.php?title=Обучающая_выборка) и [*контрольную*](http://www.machinelearning.ru/wiki/index.php?title=Контрольная_выборка). Для каждого разбиения выполняется настройка [алгоритма](http://www.machinelearning.ru/wiki/index.php?title=Алгоритм) по обучающей подвыборке, затем оценивается его средняя ошибка на объектах контрольной подвыборки. *Оценкой скользящего контроля* называется средняя по всем разбиениям величина ошибки на контрольных подвыборках.

Если выборка независима, то средняя ошибка *скользящего контроля* даёт несмещённую оценку вероятности ошибки.  Это выгодно отличает её от средней ошибки на обучающей выборке, которая  может оказаться смещённой (оптимистически заниженной) оценкой  вероятности ошибки, что связано с [явлением переобучения](http://www.machinelearning.ru/wiki/index.php?title=Переобучение). 

*Скользящий контроль* является стандартной методикой тестирования и сравнения алгоритмов [классификации](http://www.machinelearning.ru/wiki/index.php?title=Классификация), [регрессии](http://www.machinelearning.ru/wiki/index.php?title=Регрессия) и [прогнозирования](http://www.machinelearning.ru/wiki/index.php?title=Прогнозирование).

> Рассматривается задача [обучения с учителем](http://www.machinelearning.ru/wiki/index.php?title=Обучение_с_учителем).

> Пусть  ![X](http://www.machinelearning.ru/mimetex/?X) — множество описаний объектов,  ![Y](http://www.machinelearning.ru/mimetex/?Y) — множество допустимых ответов. 

> Задана конечная выборка прецедентов ![X^L = (x_i,y_i)_{i=1}^L \subset X\times Y](http://www.machinelearning.ru/mimetex/?X^L = (x_i,y_i)_{i=1}^L \subset X\times Y).

> Задан [алгоритм обучения](http://www.machinelearning.ru/wiki/index.php?title=Алгоритм_обучения) — отображение  ![\mu](http://www.machinelearning.ru/mimetex/?\mu), которое произвольной конечной выборке прецедентов ![X^m](http://www.machinelearning.ru/mimetex/?X^m) ставит в соответствие функцию (алгоритм) ![a:\:X\to Y](http://www.machinelearning.ru/mimetex/?a:\:X\to Y). 

> Качество алгоритма ![a](http://www.machinelearning.ru/mimetex/?a) оценивается по произвольной выборке прецедентов ![X^m](http://www.machinelearning.ru/mimetex/?X^m) с помощью *функционала качества* ![Q(a,X^m)](http://www.machinelearning.ru/mimetex/?Q(a,X^m)).  Для процедуры скользящего контроля не важно, как именно вычисляется этот функционал.  Как правило, он аддитивен по объектам выборки:

$$
Q(a,X^m) = \frac1{m}\sum{x_i \in X^m} \mathcal{L}(a(x_i), y_i),
$$
> где ![\mathcal{L}(a(x_i),y_i)](http://www.machinelearning.ru/mimetex/?\mathcal{L}(a(x_i),y_i)) — неотрицательная [функция потерь](http://www.machinelearning.ru/wiki/index.php?title=Функция_потерь), возвращающая величину ошибки ответа алгоритма ![a(x_i)](http://www.machinelearning.ru/mimetex/?a(x_i)) при правильном ответе ![y_i](http://www.machinelearning.ru/mimetex/?y_i).

##### Сама процедура:

Выборка ![X^L](http://www.machinelearning.ru/mimetex/?X^L) разбивается ![N](http://www.machinelearning.ru/mimetex/?N) различными способами на две непересекающиеся подвыборки: ![X^L = X^m_n \cup X^k_n](http://www.machinelearning.ru/mimetex/?X^L = X^m_n \cup X^k_n),  где  ![X^m_n](http://www.machinelearning.ru/mimetex/?X^m_n) — обучающая подвыборка длины *m*, ![X^k_n](http://www.machinelearning.ru/mimetex/?X^k_n) — контрольная подвыборка длины ![k=L-m](http://www.machinelearning.ru/mimetex/?k=L-m), ![n=1,\ldots,N](http://www.machinelearning.ru/mimetex/?n=1,\ldots,N) — номер разбиения.

Для каждого разбиения *n* строится алгоритм  ![a_n = \mu(X^m_n)](http://www.machinelearning.ru/mimetex/?a_n = \mu(X^m_n)) и вычисляется значение функционала качества  ![Q_n = Q (a_n, X^k_n)](http://www.machinelearning.ru/mimetex/?Q_n = Q (a_n, X^k_n)). Среднее арифметическое значений ![Q_n](http://www.machinelearning.ru/mimetex/?Q_n) по всем разбиениям называется *оценкой скользящего контроля*:
$$
CV(\mu, X^L) = \frac1{N}\sum_{n=1}^{N}Q(\mu(X^m_n), X^k_n)
$$

> Различные варианты скользящего контроля отличаются видами функционала качества и способами разбиения выборки.

> k-fold cross validation -- k = 5:

![](img\grid_search_cross_validation.png)

#### Регуляризация на примере линейной регрессии

Задача линейной регрессии: https://habr.com/en/company/ods/blog/322076/

Давайте ограничим пространство гипотез только линейными функциями от m + 1 аргумента, будем считать, что нулевой признак для всех объектов равен единице $x_0 = 1$

$$\Large \begin{array}{rcl} \forall h \in \mathcal{H}, h\left(\overline{x}\right) &=& w_0 x_0 + w_1 x_1 + w_2 x_2 + \cdots + w_m x_m \\ &=& \sum_{i=0}^m w_i x_i \\ &=& \overline{x}^T \overline{w} \end{array}$$

 Эмпирический риск (функция стоимости) принимает форму среднеквадратичной ошибки:

$$\Large \begin{array}{rcl}\mathcal{L}\left(X, \overline{y}, \overline{w} \right) &=& \frac{1}{2n} \sum_{i=1}^n \left(y_i - \overline{x}_i^T \overline{w}_i\right)^2 \\ &=& \frac{1}{2n} \left\| \overline{y} - X \overline{w} \right\|_2^2 \\ &=& \frac{1}{2n} \left(\overline{y} - X \overline{w}\right)^T \left(\overline{y} - X \overline{w}\right) \end{array}$$

строки матрицы $X$— это признаковые описания наблюдаемых объектов. Один из алгоритмов обучения $M$ такой модели — это метод наименьших квадратов. Вычислим производную функции стоимости:

$\Large \begin{array}{rcl} \frac{\partial \mathcal{L}}{\partial \overline{w}} &=& \frac{\partial}{\partial \overline{w}} \frac{1}{2n} \left( \overline{y}^T \overline{y} -2\overline{y}^T X \overline{w} + \overline{w}^T X^T X \overline{w}\right) \\ &=& \frac{1}{2n} \left(-2 X^T \overline{y} + 2X^T X \overline{w}\right) \end{array}$

приравняем к нулю и найдем решение в явном виде:

$$\Large \begin{array}{rcl} \frac{\partial \mathcal{L}}{\partial \overline{w}} = 0 &\Leftrightarrow& \frac{1}{2n} \left(-2 X^T \overline{y} + 2X^T X \overline{w}\right) = 0 \\ &\Leftrightarrow& -X^T \overline{y} + X^T X \overline{w} = 0 \\ &\Leftrightarrow& X^T X \overline{w} = X^T \overline{y} \\ &\Leftrightarrow& \overline{w} = \left(X^T X\right)^{-1} X^T \overline{y} \end{array}$$

Сложный функционал содержит регуляризацию, которая обычно представлена в виде дополнительного регуляризационного слагаемого: $min\ L(X,y,w) + λ F(w)$, где  $L(X,y,w)$ — функция потерь, $F(w)$ — регуляризационная функция, $λ$ — параметр, задающий степень влияния регуляризации.
 Регуляризация предназначена для регулирования сложности модели и ее  целью является упрощение модели. Это, в частности, помогает бороться с  переобучением и позволяет увеличить обобщающую способность модели.

 Типичные примеры регуляризационных функций:

1. $L_1 = ∑ |w|$
    Известная как LASSO-регуляризация (Least Absolute Shrinkage and  Selection Operator), и, как несложно догадаться из названия, она  позволяет снижать размерность коэффициентов, обращая некоторые из них в  нули. И это весьма удобно, когда исходные данные сильно коррелированы.

2. $L_2 = ∑ w^2$
    Иногда ее называют ridge-регуляризацией (гребневая), и она позволяет минимизировать  значения коэффициентов модели, а заодно сделать ее робастной к  незначительным изменениям исходных данных. А еще она хорошо  дифференцируется, а значит модель можно рассчитать аналитически.

3. $L_{EN} = α L_1 + (1 — α) L_2$
    Совмещая LASSO и ridge, получаем ElasticNet, которая объединяет два мира со всеми их плюсами и минусами.

$w, \beta$ -- это одно и тоже (параметры модели)

![](img\Ridge_and_Lasso.png)

> Продублируем наглядный пример из статьи о [ вариациях регрессии](https://neerc.ifmo.ru/wiki/index.php?title=Вариации_регрессии). Рассмотрим для простоты двумерное пространство независимых переменных. В случае лассо регрессии ограничение на коэффициенты представляет собой  ромб $(|β_1|+|β_2|≤ t)$, в случае гребневой регрессии — круг $(β^2_1+β^2_2≤t^2)$. Необходимо минимизировать функцию ошибки, но при этом соблюсти  ограничения на коэффициенты. С геометрической точки зрения задача  состоит в том, чтобы найти точку касания линии, отражающей функцию  ошибки с фигурой, отражающей ограничения на *β*. Из рисунка интуитивно понятно, что в случае лассо регрессии эта точка с  большой вероятностью будет находиться на углах ромба, то есть лежать на  оси, тогда как в случае гребневой регрессии такое происходит очень  редко. Если точка пересечения лежит на оси, один из коэффициентов будет  равен нулю, а значит, значение соответствующей независимой переменной не будет учитываться.


