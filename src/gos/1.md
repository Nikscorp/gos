# 1. Последовательная и параллельная сложность алгоритмов, информационный граф и ресурс параллелизма алгоритмов.

**Последовательная сложность** (serial complexity) алгоритма — число операций, которые нужно выполнить при его последовательном исполнении.

**Параллельная сложность** (parallel complexity) алгоритма — число шагов, за которое можно выполнить данный алгоритм в предположении доступности неограниченного числа необходимых процессоров (функциональных устройств, вычислительных узлов, ядер и т.п.). Параллельная сложность алгоритма понимается как высота канонической [ярусно-параллельной формы](https://algowiki-project.org/ru/Глоссарий#.D0.AF.D1.80.D1.83.D1.81.D0.BD.D0.BE-.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D1.8C.D0.BD.D0.B0.D1.8F_.D1.84.D0.BE.D1.80.D0.BC.D0.B0_.D0.B3.D1.80.D0.B0.D1.84.D0.B0_.D0.B0.D0.BB.D0.B3.D0.BE.D1.80.D0.B8.D1.82.D0.BC.D0.B0).

**Ярусно-параллельная форма (ЯПФ)** (parallel form) — это представление графа алгоритма, в котором:

-    все вершины разбиты на перенумерованные подмножества ярусов;

-    начальная вершина каждой дуги расположена на ярусе с номером меньшим, чем номер яруса конечной вершины;

-    между вершинами, расположенными на одном ярусе, не может быть дуг.

*Высота* ЯПФ — это число ярусов. Ширина яруса — число вершин, расположенных на ярусе. *Ширина* ЯПФ — это максимальная ширина ярусов в ЯПФ.

**Канонической ярусно-параллельной формой** называется ЯПФ, высота которой на единицу больше длины критического пути (самого длинного пути), а все входные вершины расположены на первом ярусе. Для заданного графа его каноническая ЯПФ единственна. 

**Граф алгоритма** (algorithm graph, информационный граф) — это ориентированный ациклический мультиграф, вершины которого соответствуют операциям алгоритма, а дуги — передаче данных между ними. Вершины графа алгоритма могут соединяться несколькими дугами, в частности когда в качестве разных аргументов одной и той же операции используется одна и та же величина. Граф алгоритма почти всегда является параметризованным графом. В частности, его вид часто зависит от входных данных.

![](img\aaaaaa.png)

*Рисунок 1: Информационная структура одного из вариантов алгоритма решения систем  линейных алгебраических уравнений с блочно-двухдиагональной матрицей*

Граф алгоритма используется как удобное представление алгоритма при исследовании его структуры, ресурса параллелизма, а также других свойств. Его можно рассматривать как параметризованную информационную историю. Он сохраняет её информативность, при этом обладая компактностью за счёт параметризации. Разработана методика построения графа алгоритма по исходному тексту программ.

*Граф алгоритма*:

-    почти всегда является параметризованным графом. В частности, его вид часто зависит от входных данных.

-    используется как удобное представление алгоритма при исследовании его структуры, ресурса параллелизма, а также других свойств.

-    показывает как устроена параллельная структура алгоритма. Много информации несут разного рода проекции информационного графа, выделяя его регулярные составляющие и одновременно скрывая несущественные детали.

-    потенциально бесконечный граф, число вершин и дуг которого определяется значениями внешних переменных.

-    потенциально многомерный объект. Наиболее естественная система координат для размещения вершин и дуг информационного графа опирается на структуру вложенности циклов в реализации алгоритма.

Информационная независимость определяет ресурс параллелизма программы. Ресурс параллелизма — это то, насколько хорошо данный алгоритм может быть распараллелен. Таким образом, ресурс бывает хорошим и плохим.

Для описания **ресурса параллелизма** алгоритма (ресурса параллелизма информационного графа) необходимо указать ключевые параллельные ветви в терминах [*конечного*](http://algowiki-project.org/ru/Глоссарий#.D0.9A.D0.BE.D0.BD.D0.B5.D1.87.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC) и [*массового*](http://algowiki-project.org/ru/Глоссарий#.D0.9C.D0.B0.D1.81.D1.81.D0.BE.D0.B2.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC) параллелизма. Далеко не всегда ресурс параллелизма выражается просто, например, через [*координатный параллелизм*](http://algowiki-project.org/ru/Глоссарий#.D0.9A.D0.BE.D0.BE.D0.BE.D0.B4.D0.B8.D0.BD.D0.B0.D1.82.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC) или, что то же самое, через независимость итераций некоторых циклов (да-да-да, циклы — это понятие, возникающее лишь на этапе реализации, но здесь все так связано… В данном случае, координатный параллелизм означает, что информационно независимые вершины лежат на гиперплоскостях, перпендикулярных одной из координатных осей). С этой точки зрения, не менее важен и ресурс [*скошенного параллелизма*](http://algowiki-project.org/ru/Глоссарий#.D0.A1.D0.BA.D0.BE.D1.88.D0.B5.D0.BD.D0.BD.D1.8B.D0.B9_.D0.BF.D0.B0.D1.80.D0.B0.D0.BB.D0.BB.D0.B5.D0.BB.D0.B8.D0.B7.D0.BC). В отличие от координатного параллелизма, скошенный параллелизм намного сложнее использовать на практике, но знать о нем необходимо, поскольку иногда других вариантов и не остается: нужно оценить потенциал алгоритма, и лишь после этого, взвесив все альтернативы, принимать решение о конкретной параллельной реализации. Хорошей иллюстрацией может служить алгоритм, структура которого показана на рис.1: координатного параллелизма нет, но есть параллелизм скошенный, использование которого снижает сложность алгоритма с $n \times m$ в последовательном случае до $(n+m-1)$ в параллельном варианте.

![01_33](img/01_33.jpg)

**Конечный параллелизм (finite parallelism)** — параллелизм, определяемый информационной независимостью некоторых фрагментов в тексте программы.

**Массовый параллелизм (mass parallelism)** — параллелизм, определяемый информационной независимостью итераций циклов программы.

**Координатный параллелизм (coordinate parallelism)** — частный случай скошенного параллелизма, определяемый циклами ParDO, при котором информационно независимые вершины лежат на гипер-плоскостях, перпендикулярных одной из координатных осей.

**Скошенный параллелизм (skewed parallelism)** — параллелизм в пространстве итераций, определяемый поверхностями уровней разверток. Ряд исследователей этим термином пользуется только для случая, когда параллелизм не является координатным.

Все можно найти на алговики —  https://goo.gl/0AtOj7

Про граф алгоритма (инфо граф) — [https://ru.wikipedia.org/wiki/Граф_алгоритма](https://ru.wikipedia.org/wiki/Граф_алгоритма)

## Возможные допы

### Закон Амдала

> Напрямую связан с темой билета

Пусть необходимо решить некоторую вычислительную задачу. Предположим, что её алгоритм таков, что доля $\alpha$ от общего объёма вычислений может быть получена только последовательными расчётами, а, соответственно, доля $1-\alpha$  может быть распараллелена идеально (то есть время вычисления будет обратно пропорционально числу задействованных узлов $p$). Тогда ускорение, которое может быть получено на вычислительной системе из $p$ процессоров, по сравнению с однопроцессорным решением не будет превышать величины:

$S_{p}={\cfrac  {1}{\alpha +{\cfrac  {1-\alpha }{p}}}}$

### Закон Мура

> Раз уж заговорили про законы

**Закон Мура** — эмпирическое наблюдение, изначально сделанное Гордоном Муром, согласно которому (в современной формулировке) количество транзисторов, размещаемых на кристалле интегральной схемы, удваивается каждые 24 месяца.

В последнее время, чтобы получить возможность задействовать на практике ту дополнительную вычислительную мощность, которую предсказывает закон Мура, стало необходимо задействовать параллельные вычисления. На протяжении многих лет производители процессоров постоянно увеличивали тактовую частоту и параллелизм на уровне инструкций, так что на новых процессорах старые однопоточные приложения исполнялись быстрее без каких-либо изменений в программном коде. Примерно с середины десятилетия 2000-х годов по разным причинам производители процессоров предпочитают многоядерные архитектуры, и для получения всей выгоды от возросшей производительности ЦП программы должны переписываться в соответствующей манере. Однако не каждый алгоритм поддается распараллеливанию, определяя, таким образом, фундаментальный предел эффективности решения вычислительной задачи согласно закону Амдала.
